{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figuring out method 1, i might need a pom.xml file; jar to be auto downloaded from maven coordinates\n",
    "# second config worked as the jar is available on local dir. first method, i think the container doesnt hv access to the internet will investigate.\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"DataSourcesJDBC\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\", \"org.postgresql:postgresql:42.7.2\"\n",
    "    )\n",
    "    .config(\n",
    "        \"spark.driver.extraClassPath\", \"/pysparkdata/postgresql-42.7.2.jar\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LearningSparkV2  postgresql-42.7.2.jar\tSparkDefinitive\n"
     ]
    }
   ],
   "source": [
    "!ls /pysparkdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2 if jar files are locally downloaded\n",
    "spark = SparkSession.builder.appName(\"DataSource\") \\\n",
    "    .config(\"spark.jars.packages\", \"/data/postgresql-42.7.2.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''our DB connection PARAMETERS.'''\n",
    "\n",
    "host = \"learnpyspark-postgres-1\" #Name of the container is the host\n",
    "port = 5432\n",
    "user = \"postgres\"\n",
    "password = \"password\"\n",
    "database = \"testdb\"\n",
    "dbtbl = \"testtable\"\n",
    "url = f\"jdbc:postgresql://{host}:{port}/{database}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- custname: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- tel: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reading from the postgres database\n",
    "jdbcDF = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", dbtbl) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .load()\n",
    "\n",
    "jdbcDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---------------+------+\n",
      "| id|custname|          email|   tel|\n",
      "+---+--------+---------------+------+\n",
      "|  1|   moris|    moris@gmail|  3540|\n",
      "|  2|    mumo|     mumo@gmail|  5689|\n",
      "|  3|   masua|    masua@gmail|  6398|\n",
      "|  4| Charlie|charlie@example|987654|\n",
      "|  5|   Alice|  alice@example|123456|\n",
      "|  6|     Bob|    bob@example|654321|\n",
      "|  7|     vee|      vee@gmail|  5478|\n",
      "|  8|   daisy|    daisy@gmail|  7778|\n",
      "+---+--------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jdbcDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+------+\n",
      "|custname|          email|   tel|\n",
      "+--------+---------------+------+\n",
      "|   Alice|  alice@example|123456|\n",
      "|     Bob|    bob@example|654321|\n",
      "| Charlie|charlie@example|987654|\n",
      "+--------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reading to the postgres database. step1 -load or creat a df, step2 - save to db\n",
    "data = [\n",
    "    (\"Alice\", \"alice@example\", 123456),\n",
    "    (\"Bob\", \"bob@example\", 654321),\n",
    "    (\"Charlie\", \"charlie@example\", 987654),\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = spark.createDataFrame(data, schema=\"custname string, email string, tel int\")\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING append mode and the save()\n",
    "df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .mode('append') \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", dbtbl) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
