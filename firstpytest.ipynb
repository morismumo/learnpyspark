{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel) (firstpytest.ipynb)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Unable to get resolved server information for ms-toolsai.jupyter:_builtin.jupyterServerUrlProvider:87bc7278-7160-4546-8aeb-8c43227dad7e"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"EnvironmentTest\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3f3f4b793631:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>EnvironmentTest</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fae0fb66350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset option1\n",
    "df_pyspark=spark.read.option(key='header',value='True').csv('/data/data.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataset option2\n",
    "df_pyspark=spark.read.csv('/data/data.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- lng: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Dorothy Johnson', age=34, street='2381 Robert Pines Suite 458', city='Alyssaport', state='Montana', zip=22142, lng=132.545626, lat=-58.349095),\n",
       " Row(name='Peter Martin', age=29, street='120 Perkins Path Apt. 211', city='Fisherland', state='Tennessee', zip=88765, lng=-40.037116, lat=-39.3496665),\n",
       " Row(name='Jennifer Good', age=73, street='11873 Fuller Centers', city='North Josephburgh', state='Wisconsin', zip=95791, lng=45.677852, lat=-6.35988)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.tail(5)\n",
    "#head & tail\n",
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|           name|\n",
      "+---------------+\n",
      "|Dorothy Johnson|\n",
      "|   Peter Martin|\n",
      "|  Jennifer Good|\n",
      "+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select a column\n",
    "df_pyspark.select('name').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+\n",
      "|           name|age|\n",
      "+---------------+---+\n",
      "|Dorothy Johnson| 34|\n",
      "|   Peter Martin| 29|\n",
      "|  Jennifer Good| 73|\n",
      "+---------------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select multiple columns\n",
    "df_pyspark.select(['name','age']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'),\n",
       " ('age', 'int'),\n",
       " ('street', 'string'),\n",
       " ('city', 'string'),\n",
       " ('state', 'string'),\n",
       " ('zip', 'int'),\n",
       " ('lng', 'double'),\n",
       " ('lat', 'double')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the data types\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+-----------------+--------------------+----------------+-------+-----------------+------------------+------------------+\n",
      "|summary|           name|              age|              street|            city|  state|              zip|               lng|               lat|\n",
      "+-------+---------------+-----------------+--------------------+----------------+-------+-----------------+------------------+------------------+\n",
      "|  count|           1000|             1000|                1000|            1000|   1000|             1000|              1000|              1000|\n",
      "|   mean|           NULL|           47.972|                NULL|            NULL|   NULL|        50932.618| 3.823100903999998|1.9906343310000005|\n",
      "| stddev|           NULL|18.78995152410666|                NULL|            NULL|   NULL|28919.88486191643|102.74786675511103| 50.82377421062967|\n",
      "|    min|Aaron Whitehead|               18|00160 Young Roads...|      Acostaport|Alabama|              647|       -179.745358|        -89.885701|\n",
      "|    max|  Zachary Jones|               80|997 Glenn Greens ...|Zimmermanborough|Wyoming|            99899|        178.488026|        89.9768385|\n",
      "+-------+---------------+-----------------+--------------------+----------------+-------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+--------------------+-----------------+---------+-----+----------+-----------+--------+\n",
      "|           name|age|              street|             city|    state|  zip|       lng|        lat|agelater|\n",
      "+---------------+---+--------------------+-----------------+---------+-----+----------+-----------+--------+\n",
      "|Dorothy Johnson| 34|2381 Robert Pines...|       Alyssaport|  Montana|22142|132.545626| -58.349095|      59|\n",
      "|   Peter Martin| 29|120 Perkins Path ...|       Fisherland|Tennessee|88765|-40.037116|-39.3496665|      54|\n",
      "|  Jennifer Good| 73|11873 Fuller Centers|North Josephburgh|Wisconsin|95791| 45.677852|   -6.35988|      98|\n",
      "+---------------+---+--------------------+-----------------+---------+-----+----------+-----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adding a column\n",
    "df_pyspark.withColumn(\"agelater\",df_pyspark['age']+25).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+--------------------+-----------------+---------+-----+----------+-----------+\n",
      "|           name|age|              street|             city|    state|  zip|       lng|        lat|\n",
      "+---------------+---+--------------------+-----------------+---------+-----+----------+-----------+\n",
      "|Dorothy Johnson| 34|2381 Robert Pines...|       Alyssaport|  Montana|22142|132.545626| -58.349095|\n",
      "|   Peter Martin| 29|120 Perkins Path ...|       Fisherland|Tennessee|88765|-40.037116|-39.3496665|\n",
      "|  Jennifer Good| 73|11873 Fuller Centers|North Josephburgh|Wisconsin|95791| 45.677852|   -6.35988|\n",
      "+---------------+---+--------------------+-----------------+---------+-----+----------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropping a column\n",
    "df_pyspark.drop('agelater').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19825.18s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "/bin/bash: line 1: ./bin/run-example: No such file or directory\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata=spark.read.csv('/data/mnm_dataset.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "ca_count_mydata=(mydata\n",
    "                 .select(['State', 'Color', 'Count'])\n",
    "                 .where(mydata.State=='CA')\n",
    "                 .groupBy(['State', 'Color'])\n",
    "                 .agg(count('Count').alias('Total'))\n",
    "                 .orderBy('Total',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   CA| Green| 1723|\n",
      "|   CA| Brown| 1718|\n",
      "|   CA|Orange| 1657|\n",
      "|   CA|   Red| 1656|\n",
      "|   CA|  Blue| 1603|\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ca_count_mydata.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
